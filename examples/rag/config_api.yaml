# RAG Config
rag:
  postprocessor:
    pp_modules:
      - type: chunker
        args:
          chunking_strategy: sentence
          # text_chunker_config:
          #   threshold: 0.5
    output:
      output_path: ./tmp/my_docs
      save_each_step: True
  # LLM Config
  llm: 
    llm_name: gemma3:4b
    max_new_tokens: 5000
    temperature: 0.8
    organization: OLLAMA
    base_url: http://ollama-server:11434
  # Retriever Config
  retriever:
    db:
      uri: http://standalone:19530
      name: default
    hybrid_search_weight: 0.5
    k: 5
    collection_name: def_docs
    # Dense Model Config
    dense_config:
      model_name: dengcao/Qwen3-Embedding-0.6B:Q8_0
      organization: OLLAMA
      base_url: http://ollama-server:11434
    # Sparse Model Config
    sparse_config:
      model_name: naver/splade-cocondenser-selfdistil
  # Prompt Args
  system_prompt: "Answer the question using only the provided context.\n\nContext: {context}. If there is no relevant information, say 'I don't know'."
# Mode Config
mode: api
mode_args:
  endpoint: '/rag'
  port: 8000
  host: '0.0.0.0'
