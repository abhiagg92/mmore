# RAG Config
rag:
  postprocessor:
    pp_modules:
      - type: chunker
        args:
          chunking_strategy: sentence
          # text_chunker_config:
          #   threshold: 0.5
    output:
      output_path: ./tmp/my_docs
      save_each_step: True
  # LLM Config
  llm: 
    llm_name: gemma3:4b # "epfl-llm/meditron-70b" # "gpt-4o-mini" # Anything supported
    max_new_tokens: 5000
    temperature: 0.8
    organization: OLLAMA
    base_url: http://ollama-server:11434
  # Retriever Config
  retriever:
    db:
      uri: http://standalone:19530
      name: default
    hybrid_search_weight: 0.5
    k: 5
    collection_name: def_docs
  # Prompt Args
  system_prompt: "Answer the question using the context.\n\nContext: {context}"
# Mode Config
mode: api
mode_args:
  endpoint: '/rag'
  port: 8000
  host: '0.0.0.0'
